{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20098fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Process 2766 Shared-Data created for Single Process\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './knowledge_base/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './knowledge_base/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './knowledge_base/vdb_chunks.json'} 0 data\n",
      "INFO: Process 2766 initialized updated flags for namespace: [full_docs]\n",
      "INFO: Process 2766 ready to initialize storage namespace: [full_docs]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [text_chunks]\n",
      "INFO: Process 2766 ready to initialize storage namespace: [text_chunks]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [entities]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [relationships]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [chunks]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [chunk_entity_relation]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [llm_response_cache]\n",
      "INFO: Process 2766 ready to initialize storage namespace: [llm_response_cache]\n",
      "INFO: Process 2766 initialized updated flags for namespace: [doc_status]\n",
      "INFO: Process 2766 ready to initialize storage namespace: [doc_status]\n",
      "INFO: Process 2766 storage namespace already initialized: [full_docs]\n",
      "INFO: Process 2766 storage namespace already initialized: [text_chunks]\n",
      "INFO: Process 2766 storage namespace already initialized: [llm_response_cache]\n",
      "INFO: Process 2766 storage namespace already initialized: [doc_status]\n",
      "INFO: Process 2766 Pipeline namespace initialized\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from agents.feature.light_rag import insert_text\n",
    "# insert_text('/Users/kishorkumar/AshaAi/chat-bot-backend/dataset')\n",
    "# chat_history = [\n",
    "#     {\"role\": \"human\", \"content\": \"Hi there\"},\n",
    "#     {\"role\": \"ai\", \"content\": \"Hello! How can I help you?\"},\n",
    "#     {\"role\": \"human\", \"content\": \"Tell me about available jobs\"},\n",
    "#     {\"role\": \"ai\", \"content\": \"We have job openings in software and data science.\"}\n",
    "# ]\n",
    "# new_query = \"Can you check java job openings?\"\n",
    "\n",
    "# inputs = {\n",
    "#     \"user_query\": new_query,\n",
    "#     \"chat_history\": chat_history,\n",
    "#     \"tool_results\": {},  # optional but safe to include\n",
    "#     \"intent\": \"\",        # will be set by extract_intent\n",
    "#     \"response\": \"\",      # will be set by generate_response\n",
    "# }\n",
    "# out = core_agent.invoke(inputs)\n",
    "\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce65108",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"human\", \"content\": \"Hi there\"},\n",
    "    {\"role\": \"ai\", \"content\": \"Hello! How can I help you?\"},\n",
    "    {\"role\": \"human\", \"content\": \"Tell me about available jobs\"},\n",
    "    {\"role\": \"ai\", \"content\": \"We have job openings in software and data science.\"},\n",
    "    {\"role\": \"human\", \"content\": \"Can you check java job openings?\"},\n",
    "    {\"role\": \"ai\", \"content\": \"I can help you find Java job openings.  To give you the best results, please tell me:\\n\\n* **Location:** (e.g., San Francisco, CA; New York; Remote)\\n* **Experience level:** (e.g., Junior, Mid-level, Senior, Entry-level)* **Specific skills:** (e.g., Spring Boot, Java 8+, Microservices, Cloud Computing)\\n* **Desired salary range (optional):**  This will help narrow down the results.\\n\\nOnce I have this information, I can search for relevant job openings and provide you with a list of matching jobs.\"},\n",
    "]\n",
    "new_query = \"just check java job openings?\"\n",
    "\n",
    "inputs = {\n",
    "    \"user_query\": new_query,\n",
    "    \"chat_history\": [],\n",
    "    \"tool_results\": {},  # optional but safe to include\n",
    "    \"intent\": \"\",        # will be set by extract_intent\n",
    "    \"response\": \"\",      # will be set by generate_response\n",
    "}\n",
    "for output in core_agent.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Node '{key}':\")\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "        You are an intelligent assistant designed to classify user queries based on their intent. Always respond with only one of the following intents:\n",
    "\n",
    "            1. feature: When the user is exploring features, offerings or general questions or seeks help on common topics (e.g., how-to, what is, where to find, troubleshooting).\n",
    "            2. job: When the user asks related to jobs, events, or programs.\n",
    "            3. profile_update: When the user wants to change or manage their personal profile information(ex: skill, experience, location etc.) or expresses interest in registering, creating an account, or signing up.\n",
    "            4. unknown: When the user asks a question that does not fit into any of the above categories.\n",
    "\n",
    "            Carefully analyze the user's query and return the most suitable intent as a single lowercase string (e.g., job).\n",
    "        '''),\n",
    "        # (\"human\", \"{user_query}\"),\n",
    "    ])\n",
    "prompt.append(HumanMessage(content=\"past content\"))\n",
    "prompt.format_messages(content=\"latest msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun, DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region=\"in-en\", max_results=20)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, output_format=\"json\")\n",
    "print(search.run(\"site:indeed.com OR site:linkedin.com java jobs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba861e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install firecrawl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl.firecrawl import FirecrawlApp\n",
    "\n",
    "app = FirecrawlApp(api_key=\"fc-YOUR_API_KEY\",\n",
    "                   api_url=\"http//localhost:3002\")\n",
    "\n",
    "# Scrape a website:\n",
    "scrape_status = app.scrape_url(\n",
    "  'https://firecrawl.dev', \n",
    "  formats=[\"markdown\", \"html\"]\n",
    ")\n",
    "print(scrape_status)\n",
    "\n",
    "# Crawl a website:\n",
    "crawl_status = app.crawl_url(\n",
    "  'https://firecrawl.dev',\n",
    "  limit=100,\n",
    "  scrapeOptions={'formats': ['markdown', 'html']},\n",
    "  poll_interval=30\n",
    ")\n",
    "print(crawl_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
    "\n",
    "async def main():\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=\"https://www.google.com/search?q=java+1+year+experience+job\",\n",
    "        )\n",
    "        print(result.markdown[:300])  # Show the first 300 characters of extracted text\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from agents.wesearch_agent.web_search_agent import web_agent\n",
    "\n",
    "query = \"senior python backend engineer jobs in bengalore\"\n",
    "initial_state = {\"input\": query}\n",
    "\n",
    "# Call the LangGraph agent\n",
    "final_state = await web_agent.ainvoke(initial_state)\n",
    "\n",
    "# Print the final output\n",
    "print(\"üîç Extracted Results:\")\n",
    "for idx, result in enumerate(final_state[\"output\"]):\n",
    "    print(f\"\\n--- Result {idx+1} ---\\n{result}\\n\")\n",
    "\n",
    "# query = \"jobs in india\"\n",
    "# jobs = await run_wesearch(query)\n",
    "# for job in jobs:\n",
    "#     print(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
